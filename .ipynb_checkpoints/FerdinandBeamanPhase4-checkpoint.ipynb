{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ferdinand Beaman Phase 4 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I attempted to take about ten thousand curated tweets categorize them by their positivity. Thankfully, they have already been labeled by the helpful people here: https://data.world/crowdflower/brands-and-product-emotions\n",
    "\n",
    "My hypothetical business problem: The organizers of South by Southwest contacted me to collect public opinion about what they did right at a given year's festival in order for them to know what to emphasize next time.\n",
    "\n",
    "I considered building a ternary instead of binary classifier (positive, neutral, and then also negative), but considering both the small size of the third class and my own time remaining in the program, I decided against it.\n",
    "\n",
    "There was a class imbalance (2:1), but my research suggests that it's only moderate and not strong enough for me to intervene. With that in mind and seeing no other reasons to have special sensitivity for false negatives/positives, I predominately used accuracy scores to rank models' performances. However, if there did happen to be some major issue with either recall/precision regarding the minority class, I would take that into account.\n",
    "\n",
    "I went with a Naive Bayes classifier because it appears to be approximately as accurate as the more complex classifier while being significantly easier on both my computer and my mind.\n",
    "\n",
    "Midway, I ran into an unexpected surprise: a message in Spanish. So I spent an embarrassingly long time trying to figure out how to manage non-English languages. I searched for messages that contained no English stopwords and/or messages that contained any stopwords in common languages (excluding stopwords in those languages that are also in the English list). Ultimately, it was all for naught. I realized that either the messages would be so rare as to be essentially thrown out by the process which means they're not worth deleting *or* the messages will be common enough to matter. With that whole subsection gone, this paragraph is mostly here in memoriam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one might expect, here are the libraries I used and a preview of the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.761006Z",
     "start_time": "2024-04-05T08:22:13.200127Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/ferdi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.collocations import *\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.796185Z",
     "start_time": "2024-04-05T08:22:14.762239Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"BrandsAndProductEmotions.csv\", encoding='unicode_escape')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words following \"@\" are probably useless, and nearly all of them will be removed by the tokenization process in the future. \"Swxw\" ends up being added to the stopwords list and the rest are mostly names which will be filtered out for being too rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first edits were to the column names. Also, the last row in the DataFrame is definitely not made for human eyes so I'll just cut it right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.802399Z",
     "start_time": "2024-04-05T08:22:14.798010Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = [\"text\", \"product\", \"emotion\"]\n",
    "df.drop(df.index[9092], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there anything interesting from a macro level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.810444Z",
     "start_time": "2024-04-05T08:22:14.804213Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "No emotion toward brand or product    5388\n",
      "Positive emotion                      2978\n",
      "Negative emotion                       570\n",
      "I can't tell                           156\n",
      "Name: emotion, dtype: int64\n",
      "\n",
      "Products\n",
      "iPad                               946\n",
      "Apple                              661\n",
      "iPad or iPhone App                 470\n",
      "Google                             430\n",
      "iPhone                             297\n",
      "Other Google product or service    293\n",
      "Android App                         81\n",
      "Android                             78\n",
      "Other Apple product or service      35\n",
      "Name: product, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Value counts for the two categorical columns\n",
    "print(\"Emotion\")\n",
    "print(df.emotion.value_counts())\n",
    "print(\"\\nProducts\")\n",
    "print(df[\"product\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a visualization of our target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.913329Z",
     "start_time": "2024-04-05T08:22:14.811463Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keys = [\"No emotion\", \"Positive\", \"Negative\", \"I can't tell\"]\n",
    "values = [df[\"emotion\"].value_counts()[0], df[\"emotion\"].value_counts()[1],\n",
    "         df[\"emotion\"].value_counts()[2], df[\"emotion\"].value_counts()[3]]\n",
    "plt.barh(keys, values)\n",
    "plt.suptitle(\"Tweets per Category\", fontsize=13)\n",
    "plt.xlabel(\"Number of Tweets\", fontsize=11)\n",
    "plt.ylabel(\"Emotional Category\", fontsize=11)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T06:41:19.164476Z",
     "start_time": "2024-02-14T06:41:19.157031Z"
    }
   },
   "source": [
    "The \"Negative emotion\" class has only about 10% of the entries of the neutral class, and only 6% overall. Obviously in a real world setting I wouldn't be able to retroactively adjust my business problem, but for ease's sake it was here that I decided to probably go with a binary classifier between \"positive emotion\" and \"not positive emotion\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.923506Z",
     "start_time": "2024-04-05T08:22:14.914607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9092, 3)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9091\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     9091 non-null   object\n",
      " 1   product  3291 non-null   object\n",
      " 2   emotion  9092 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 284.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(\"\\n\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/3s of the entries are missing a product label. Also, somehow, one of the text entries is null. Suppose that's something I'll get used to the longer I work in the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.930090Z",
     "start_time": "2024-04-05T08:22:14.924712Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text product                             emotion\n",
       "6  NaN     NaN  No emotion toward brand or product"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before I forget, let me look at that null entry\n",
    "df[df[\"text\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictably, this was useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.937012Z",
     "start_time": "2024-04-05T08:22:14.933243Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(df.index[6], inplace = True)\n",
    "df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about tweets just missing product labels? Below is an arbitrary sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.941719Z",
     "start_time": "2024-04-05T08:22:14.938726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[9090][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah, this is fairly generic. How did this end up here? My assumption is that the csv file is just made up of tweets that were scraped from a specific time, possibly even from a specific area if that's possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above tweet was also pretty emotionless. Are all of the ones with missing product labels equally drab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.948095Z",
     "start_time": "2024-04-05T08:22:14.942685Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5296\n",
       "Positive emotion                       306\n",
       "I can't tell                           147\n",
       "Negative emotion                        51\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"product\"].isnull()][\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, there are emotional statements in here. This seems to be *somewhat* similar to the rest of the dataset except for a big dropoff for positive tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the more routine preprocessing tasks, there are two things I had to get out of the way: seeing if entries with NaN in the \"emotion\" column are worth keeping, and investigating the \"I can't tell\"s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unclear Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are 10 sample messages from those with NaN as the product, presumably directed at nothing in particular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.957205Z",
     "start_time": "2024-04-05T08:22:14.949566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT Hiring marketers, designers, creatives, social media pros... Come see #Aquent booth 1415 #SXSW trade show. Might win iPad 2\n",
      "\n",
      "\n",
      "RT @mention Full #SXSW #touchingstories presentation: {link}\n",
      "\n",
      "\n",
      "RT @mention #SXSW Interactive Award: Music Category goes to &quot;Wilderness Downtown&quot;. Congrats shared with @mention @mention @mention #winning\n",
      "\n",
      "\n",
      "One guy stakes out the Austin Apple popup shop at #SXSW for his #iPad 2 {link} #SXSWi\n",
      "\n",
      "\n",
      "RT @mention RT @mention Google set to launch new social network #Circles today at #sxsw\n",
      "\n",
      "\n",
      "hey @mention heard you're at #sxsw. Come by to the @mention grille and make your comic into a iPhone case? What do you say? :]\n",
      "\n",
      "\n",
      "Too bad I don't have a _ button!\n",
      "RT @mention I know its #SXSW time when I have an abnormal amount of app updates on my iPhone.\n",
      "\n",
      "\n",
      "RT @mention &quot;my kids will not grow up thinking the New York Times and Google are in separate industries&quot; @mention #bvj #SXSW\n",
      "\n",
      "\n",
      "packing for #sxsw = iPad, iPhone, BlackBerry, laptop, and video camera. Need a stylish belt-clip-gadget-holster. Or is that an oxymoron? #in\n",
      "\n",
      "\n",
      "The line outside the #SXSW Apple pop-up store. #wasteoftimeatsxsw {link}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_prod_s = df[df[\"product\"].isnull() == True].sample(n=10, random_state =2)\n",
    "for i in range(10):\n",
    "    print(null_prod_s[\"text\"].iloc[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was where I went from fairly certain to truly certain concerning the origin of the cvs file. It's just a collection of tweets that contain tech-company keywords in them. Since they do have relevant emotional words and I can assume that this is exactly the kind of data I would be working with outside of school, I kept them in the dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about those where the emotional label is \"I can't tell\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.964239Z",
     "start_time": "2024-04-05T08:22:14.958465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprando mi iPad 2 en el #SXSW (@mention Apple Store, SXSW w/ 62 others) {link}\n",
      "\n",
      "\n",
      "The queue at the Apple Store in Austin is FOUR blocks long. Crazy stuff! #sxsw\n",
      "\n",
      "\n",
      "RT @mention Demo of Google Hotpot at #bettersearch panel: still pull search, but personalized. Not yet serendipitous? #SXSW\n",
      "\n",
      "\n",
      "Why Barry Diller thinks iPad only content is nuts @mention #SXSW {link}\n",
      "\n",
      "\n",
      "Like @mention I've now seen most of Austin in Google Streetview checking out apartments for #sxsw. Austin is not easy on the click.\n",
      "\n",
      "\n",
      "Anyone know status of iPad 2s in Austin pop-up store? Sold out? Getting more? #ipad2 #sxsw\n",
      "\n",
      "\n",
      "Reports of @mention introducing a new social media platform at #SXSW were premature, but hopefully not overly optimistic {link}\n",
      "\n",
      "\n",
      "DANG RT @mention Confirmed! Apple store 2 week popup in Austin for #SXSW {link} (via @mention who gave us no credit! )\n",
      "\n",
      "\n",
      "At the Team Android party. Can't find it on Gowalla or Foursquare, so um, there you go. #sxsw\n",
      "\n",
      "\n",
      "Line for Source Code is even longer than for iPad 2. Take that, Apple. #sxsw\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Another 10-tweet sample\n",
    "ict_emo_s = df[df[\"emotion\"] == \"I can't tell\"].sample(n=10, random_state =2)\n",
    "for i in range(10):\n",
    "    print(ict_emo_s[\"text\"].iloc[i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see why these messages were left out. Any categorization that I put on them is likely to not have any inter-rater reliability. Thankfully, there aren't that many of them so I removed them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.970113Z",
     "start_time": "2024-04-05T08:22:14.965847Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[\"emotion\"].loc[df[\"emotion\"]==\"I can't tell\"].index)\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "#https://stackoverflow.com/questions/53182464/\n",
    "#pandas-delete-a-row-in-a-dataframe-based-on-a-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.974653Z",
     "start_time": "2024-04-05T08:22:14.971019Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5387\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I moved forward from here, I would likely not have enough negative tweets to create a proper ternary classifier. The classes are just too imbalanced. Perhaps I could have used up/downsampling, but instead I just  grouped them in with the neutrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.981006Z",
     "start_time": "2024-04-05T08:22:14.975525Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['emotion'] == \"No emotion toward brand or product\", \"emotion\"\n",
    "      ] = \"Not positive\" #\"Not positive\" is not synonymous with negative!\n",
    "\n",
    "df.loc[df['emotion'] == \"Negative emotion\", \"emotion\"] = \"Not positive\"\n",
    "\n",
    "df.loc[df['emotion'] == \"Positive emotion\", \"emotion\"] = \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.986019Z",
     "start_time": "2024-04-05T08:22:14.982040Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not positive    5957\n",
       "Positive        2978\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should be a comfortable enough imbalance to move forward, at least according to anything I could find on the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the Flatiron Approved preprocessing steps (lower case, remove punctuation, lemmatize), I'll also expand the contractions. It's possible that all of those words shrunk by the apostrophe are stopwords, but after seeing someone else take the extra step I figured I shouldn't take any chances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:14.999170Z",
     "start_time": "2024-04-05T08:22:14.986992Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:16.076328Z",
     "start_time": "2024-04-05T08:22:15.000732Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"processed_text\"] = \"\" \n",
    "for i in range(len(df)):\n",
    "    exp_text = []\n",
    "    for word in df[\"text\"].iloc[i].split():\n",
    "        exp_text.append(contractions.fix(word))\n",
    "    exp_text = \" \".join(exp_text)\n",
    "    df[\"processed_text\"].iloc[i] = exp_text\n",
    "    \n",
    "df.drop(\"text\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:16.079412Z",
     "start_time": "2024-04-05T08:22:16.077186Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you will likely appreciate for its design. Also, they are giving free Ts at #SXSW'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.processed_text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"You'll\" became \"you will\". Success!\n",
    "\n",
    "Now to both tokenize the text and force it all to be lowercase. Note: If this sample was taken today, more emotional information might actually be lost compared to what I actually have. Why? Because writing text LiKe thIS To DEnOtE sARCaSm is a new thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:16.794415Z",
     "start_time": "2024-04-05T08:22:16.080222Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Much of this cell was taken directly from earlier in the course\n",
    "\n",
    "basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "\n",
    "tokenizer = RegexpTokenizer(basic_token_pattern)\n",
    "for i in range(len(df)):\n",
    "    df.processed_text.iloc[i] = \" \".join(tokenizer.tokenize(\n",
    "        df.processed_text.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:16.801390Z",
     "start_time": "2024-04-05T08:22:16.795331Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"processed_text\"] = df[\"processed_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:16.806606Z",
     "start_time": "2024-04-05T08:22:16.802278Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone</td>\n",
       "      <td>Not positive</td>\n",
       "      <td>wesley83 have 3g iphone after hrs tweeting at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive</td>\n",
       "      <td>jessedee know about fludapp awesome ipad iphon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive</td>\n",
       "      <td>swonderlin can not wait for ipad also they sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Not positive</td>\n",
       "      <td>sxsw hope this year festival is not as crashy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>Positive</td>\n",
       "      <td>sxtxstate great stuff on fri sxsw marissa maye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              product       emotion  \\\n",
       "0              iPhone  Not positive   \n",
       "1  iPad or iPhone App      Positive   \n",
       "2                iPad      Positive   \n",
       "3  iPad or iPhone App  Not positive   \n",
       "4              Google      Positive   \n",
       "\n",
       "                                      processed_text  \n",
       "0  wesley83 have 3g iphone after hrs tweeting at ...  \n",
       "1  jessedee know about fludapp awesome ipad iphon...  \n",
       "2  swonderlin can not wait for ipad also they sho...  \n",
       "3  sxsw hope this year festival is not as crashy ...  \n",
       "4  sxtxstate great stuff on fri sxsw marissa maye...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks alright so far. Hopefully there's nothing extremely weird and new for me to handle next...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weird Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True duplicates are easy to find. But the strings that have caught my attention don't tend to be true duplicates. Twitter is a place where people append single names or words to messages and then pass them along, which seems to have ballooned the size of my dataset. Many of them differ by just \"rt\" or \"link\" tucked away somewhere. Or a typo.\n",
    "\n",
    "Luckily, after quite a lot of searching, I was able to find a library that handles near-duplicates. It's \"thefuzz\" (previously called fuzzywuzzy). Through its \"ratio\" method it shows you how much you would have to edit one message to create another through. This allows us to compare the similarity of two different messages, which will then be used to draw a line for where the messages can be categorized as close-enough, and can therefore be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:18.768492Z",
     "start_time": "2024-04-05T08:22:16.810860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thefuzz in /Users/ferdi/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (0.22.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in /Users/ferdi/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from thefuzz) (3.6.1)\n",
      "Requirement already satisfied: rapidfuzz in /Users/ferdi/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (3.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install thefuzz\n",
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:18.867875Z",
     "start_time": "2024-04-05T08:22:18.773410Z"
    }
   },
   "outputs": [],
   "source": [
    "from thefuzz import fuzz\n",
    "from thefuzz import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that out of the way, the following messages seem like a typical example of an original tweet and a retweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:18.871618Z",
     "start_time": "2024-04-05T08:22:18.868760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samsung sony follow apple hp lead mention link austin atx sxsw\n",
      "samsung sony follow apple hp lead mention link austin atx sxsw via mention rg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"processed_text\"][130])\n",
    "print(df[\"processed_text\"][131])\n",
    "# This is the percent similarity, rounded to the nearest whole\n",
    "fuzz.ratio(df[\"processed_text\"][130], df[\"processed_text\"][131])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T06:23:19.751714Z",
     "start_time": "2024-02-19T06:23:19.745902Z"
    }
   },
   "source": [
    "With this  example of 89% similarity, I assumeed I could expand my scope a bit. It's just a couple of extra words, right? But I wasn't sure how deep to look. where. On a whim, I tried 75%.\n",
    "\n",
    "Also, just for this section of the project, I'm only  collecting \"identical\" tweets if they are adjacent to one another in the dataframe. There are plenty to work with still, but it ended up saving a lot of time. Later on I'll remove the identical tweets regardless of position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:18.943352Z",
     "start_time": "2024-04-05T08:22:18.872413Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dup_above_75 = []\n",
    "\n",
    "for x in range(len(df)-2):\n",
    "    tweet1 = df[\"processed_text\"][x] #Just a tweet and the one right after.\n",
    "    tweet2  = df[\"processed_text\"][x+1]\n",
    "    if fuzz.ratio(tweet1, tweet2) >75:\n",
    "        dup_above_75.append(x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:18.945897Z",
     "start_time": "2024-04-05T08:22:18.944268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778\n"
     ]
    }
   ],
   "source": [
    "print(len(dup_above_75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "778 duplicates, just for adjacent tweets. That's a pretty big fraction. If there were a lot of duplicates scattered about the DF it seemed possible that I might end up removing a thousand messages, maybe even 2 thousand. A scary thought, concerning the robustness of my data, but thankfully it didn't quite come true.\n",
    "\n",
    "In any case, it struck me that just a couple of extra words at the end of a message could change the meaning. So how many of these duplicates have different emotional categorizations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:21.641001Z",
     "start_time": "2024-04-05T08:22:18.946788Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57.898058154945986, 100.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preparing a graph, relating the similarity of tweets to the likelihood\n",
    "#of them being categorized the same way\n",
    "Y_axis = []\n",
    "X_axis = []\n",
    "for percent in range(40,101, 3):\n",
    "    diff_emo = 0\n",
    "    dupes = 0\n",
    "    for x in range(len(df)-2):\n",
    "        tweet1 = df[\"processed_text\"][x]\n",
    "        tweet2  = df[\"processed_text\"][x+1]\n",
    "        emo1 = df[\"emotion\"][x]\n",
    "        emo2 = df[\"emotion\"][x+1]\n",
    "        ratio = fuzz.ratio(tweet1, tweet2)\n",
    "        if (ratio >= percent) & (emo1 == emo2):\n",
    "            dupes += 1\n",
    "            diff_emo += 1\n",
    "        elif ratio >= percent:\n",
    "            dupes += 1\n",
    "        else:\n",
    "            pass\n",
    "    X_axis.append(percent)\n",
    "    Y_axis.append(100*(diff_emo/dupes))\n",
    "\n",
    "plt.plot(X_axis, Y_axis, \"b\")\n",
    "plt.grid(which=\"both\")\n",
    "plt.xlabel(\"Identical Text Percentage\", fontsize = 12)\n",
    "plt.ylabel(\"Chance of Shared Label\", fontsize = 12)\n",
    "plt.suptitle(\"Ambiguity: Text Overlap x Label Overlap\", fontsize = 14)\n",
    "plt.ylim(top = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was wildly unexpected. Even identical tweets are only matching about 82% of the time! How is that possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:21.768537Z",
     "start_time": "2024-04-05T08:22:21.641958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at sxsw apple schools the marketing experts link\n",
      "at sxsw apple schools the marketing experts link\n",
      "Positive\n",
      "Not positive\n",
      "100\n",
      "\n",
      "\n",
      "does your smallbiz need reviews to play on google places we got an app for that link seo sxsw\n",
      "does your smallbiz need reviews to play on google places we got an app for that link seo sxsw\n",
      "Positive\n",
      "Not positive\n",
      "100\n",
      "\n",
      "\n",
      "at sxsw apple schools the marketing experts link\n",
      "at sxsw apple schools the marketing experts link\n",
      "Not positive\n",
      "Positive\n",
      "100\n",
      "\n",
      "\n",
      "mention google will connect the digital amp physical worlds through mobile link sxsw rt mention\n",
      "mention google will connect the digital amp physical worlds through mobile link sxsw rt mention\n",
      "Positive\n",
      "Not positive\n",
      "100\n",
      "\n",
      "\n",
      "win free ipad from webdoc com sxsw rt\n",
      "win free ipad from webdoc com sxsw rt\n",
      "Not positive\n",
      "Positive\n",
      "100\n",
      "\n",
      "\n",
      "rt mention what is going on at sxsw today share photos video with ireport link or through cnn iphone app\n",
      "rt mention what is going on at sxsw today share photos video with ireport link or through cnn iphone app\n",
      "Positive\n",
      "Not positive\n",
      "100\n",
      "\n",
      "\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "Positive\n",
      "Not positive\n",
      "100\n",
      "\n",
      "\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "Not positive\n",
      "Positive\n",
      "100\n",
      "\n",
      "\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "Positive\n",
      "Not positive\n",
      "100\n",
      "\n",
      "\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "Not positive\n",
      "Positive\n",
      "100\n",
      "\n",
      "\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "rt mention marissa mayer google will connect the digital amp physical worlds through mobile link sxsw\n",
      "Positive\n",
      "Not positive\n",
      "100\n",
      "\n",
      "\n",
      "rt mention rt mention it is not rumor apple is opening up temporary store in downtown austin for sxsw and the ipad2 launch link\n",
      "rt mention rt mention it is not rumor apple is opening up temporary store in downtown austin for sxsw and the ipad launch link\n",
      "Not positive\n",
      "Positive\n",
      "100\n",
      "\n",
      "\n",
      "rt mention rt mention it is not rumor apple is opening up temporary store in downtown austin for sxsw and the ipad launch link\n",
      "rt mention rt mention it is not rumor apple is opening up temporary store in downtown austin for sxsw and the ipad launch link\n",
      "Positive\n",
      "Not positive\n",
      "100\n",
      "\n",
      "\n",
      "score free am going to tshirt outside the sxsw apple store today at 15 pm amp check out am going to app for the ipad link sxsw ipad2\n",
      "score free am going to tshirt outside the sxsw apple store today at 15 pm amp check out am going to app for the ipad link sxsw ipad2\n",
      "Not positive\n",
      "Positive\n",
      "100\n",
      "\n",
      "\n",
      "apple set to open popup shop in core of sxsw action in downtown austin link ipad\n",
      "apple set to open popup shop in core of sxsw action in downtown austin link ipad\n",
      "Not positive\n",
      "Positive\n",
      "100\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Collecting just the identical ones\n",
    "for x in range(len(df)-2):\n",
    "    tweet1 = df[\"processed_text\"][x]\n",
    "    tweet2  = df[\"processed_text\"][x+1]\n",
    "    emo1 = df[\"emotion\"][x]\n",
    "    emo2 = df[\"emotion\"][x+1]\n",
    "    ratio = fuzz.ratio(tweet1, tweet2)\n",
    "    if (ratio == 100) & (emo1 != emo2):\n",
    "        print(tweet1) # Verifying that the text is the same\n",
    "        print(tweet2)\n",
    "        print(emo1) # Verifying that the emotions are different\n",
    "        print(emo2)\n",
    "        print(ratio)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first reaction to these identical tweets getting two different scores was to panic. But, looking at them more, I think that these are tweets that perhaps should have been labeled with \"I can't tell\", if only the raters were less confident in their own abilities. The fact that two different people (or the same person twice) rated them differently is a bit annoying. But I can see how this would happen.\n",
    "\n",
    "To untangle this, I found a semi-arbitrary cutoff where any difference in categorization was likely to be because of the difference in text as opposed to a difference in interpretation. Anything more similar than that cutoff will be taken out of the population. Hopefully, this means my NLP algorithm will be dealing with less ambiguous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:22.247184Z",
     "start_time": "2024-04-05T08:22:21.769652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "80\n",
      "40 of google maps usage is mobile now has 150 million mobile users sxsw via mention\n",
      "40 of google maps usage is mobile wow mention sxsw via mention\n",
      "\n",
      "\n",
      "rt mention quot google before you tweet is the new think before you speak quot belinsky of digital democracy sxsw 911tweets\n",
      "rt mention quot google before you tweet quot is the new quot think before you speak quot mark belinsky sxsw\n",
      "\n",
      "\n",
      "rt mention rt mention google set to launch new social network circles today at sxsw\n",
      "rt mention rt mention google to launch social network circles at sxsw link who is excited\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "82\n",
      "ûï mention apple store downtown austin open til midnight sxsw mention there is still time\n",
      "ûï mention apple store downtown austin open til midnight sxsw any ipad2 left in stock\n",
      "\n",
      "\n",
      "apple set to open popup shop in core of sxsw action link sxsw apple ipad retail\n",
      "apple set to open popup shop in core of sxsw action link sxsw apple apple set to open popup sh link\n",
      "\n",
      "\n",
      "rt mention apple popup store at sxsw link\n",
      "rt mention apple popup store at sxsw link sat am at opening\n",
      "\n",
      "\n",
      "rt mention apple to open temporary store for sxsw at 6th and congress link atx\n",
      "rt mention apple to open temporary store for sxsw interesting link\n",
      "\n",
      "\n",
      "rt mention at sxsw apple schools the marketing experts link sxsw\n",
      "rt mention at sxsw apple schools the marketing experts link via mention sxsw apple marketing\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "84\n",
      "google to launch major new social network called circles possibly today link sxsw gt gt should be good\n",
      "google to launch major new social network called circles possibly today link sxsw of course another social network\n",
      "\n",
      "\n",
      "apple set to open popup shop in core of sxsw action link ipad2 on the ground\n",
      "apple set to open popup shop in core of sxsw action link geeks need ipad2 love\n",
      "\n",
      "\n",
      "at sxsw apple schools the marketing experts link apple jobsco sxsw\n",
      "at sxsw apple schools the marketing experts link sxsw essdub\n",
      "\n",
      "\n",
      "the next big thing hmmm rt mention google to launch major new social network called circles possibly today link sxsw\n",
      "could be big gt gt google to launch major new social network called circles possibly today link tech sxsw\n",
      "\n",
      "\n",
      "40 of google maps use is mobile marissamayer sxsw\n",
      "40 of google maps use is mobile says mention sxsw\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "86\n",
      "at sxsw apple schools the marketing experts sxsw cnet blogs link\n",
      "at sxsw apple schools the marketing experts link\n",
      "\n",
      "\n",
      "google to launch new social network at sxsw link google sxsw\n",
      "google to launch new social network at sxsw cnet news link sxsw\n",
      "\n",
      "\n",
      "the ipad design panel in hilton salon is filling up quickly no surprises there tapworthy sxsw\n",
      "the ipad design panel in hilton salon is filling up quickly no surprises there tapworthy sxsw it is more fun with the ipad2\n",
      "\n",
      "\n",
      "rt mention come party down with mention amp google tonight at sxsw link bands food art interactive maps\n",
      "rt mention come party mention and google tonight at sxsw link bands food art ice cream nifty interactive maps\n",
      "\n",
      "\n",
      "rt mention google to launch major new social network called circles possibly today link sxsw gt gt should be good\n",
      "rt mention google to launch major new social network called circles possibly today link rt mention sxsw\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "88\n",
      "ûï mention google to launch major new social network called circles possibly today link sxsw super interesting\n",
      "ûï mention google to launch major new social network called circles possibly today link rt mention sxsw\n",
      "\n",
      "\n",
      "google to launch major new social network called circles possibly today link sxsw pakistan cwc2011\n",
      "google to launch major new social network called circles possibly today link sxsw lb via mention\n",
      "\n",
      "\n",
      "google to launch major new social network called circles possibly today link sxsw mention\n",
      "google to launch major new social network called circles possibly today link sxsw gt gt should be good\n",
      "\n",
      "\n",
      "google to launch new social network at sxsw cnet news link sxsw\n",
      "google to launch new social network at sxsw link aclu sxsw\n",
      "\n",
      "\n",
      "finally yeaayyy rt mention new ubersocial for iphone now in the app store includes uberguide to sxsw sponsored by mashable\n",
      "akhirnya ûï mention new ubersocial for iphone now in the app store includes uberguide to sxsw sponsored by link\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "90\n",
      "google to launch major new social network called circles possibly today updated at sxsw link\n",
      "google to launch major new social network called circles possibly today updated by mention link sxsw\n",
      "\n",
      "\n",
      "google to launch major new social network called circles possibly today link\n",
      "google to launch major new social network called circles possibly today link via mention sxsw\n",
      "\n",
      "\n",
      "google to launch major new social network called circles possibly today link sxsw mention\n",
      "google to launch major new social network called circles possibly today link sxsw pakistan cwc2011\n",
      "\n",
      "\n",
      "check out the free mention sampler on itunes link sxsw\n",
      "check out the free sxsw sampler on itunes link sxsw\n",
      "\n",
      "\n",
      "marissa mayer google will connect the digital amp physical worlds through mobile link mobile sxsw\n",
      "marissa mayer google will connect the digital amp physical worlds through mobile link google sxsw mobile hotpot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "92\n",
      "ûï mention google to launch major new social network called circles possibly today link sxsw mention\n",
      "ûï mention google to launch major new social network called circles possibly today link sxsw mention bigger than gaga\n",
      "\n",
      "\n",
      "google to launch major new social network called circles link sxsw via mention\n",
      "google to launch major new social network called circles link sxsw\n",
      "\n",
      "\n",
      "check out this video to get glimpse at what the action was like the ipad ipad sxsw gadgets link\n",
      "check out this video to get glimpse at what the action was like the ipad ipad sxsw gadgets link could not resist\n",
      "\n",
      "\n",
      "apple set to open popup shop in core of sxsw action link sxsw apple\n",
      "apple set to open popup shop in core of sxsw action link sxsw apple ipad retail\n",
      "\n",
      "\n",
      "rt mention quot google before you tweet quot is the new quot think before you speak quot mark belinsky sxsw\n",
      "rt mention quot google before you tweet quot is the new quot think before you speak quot mark belinsky 911tweets panel at sxsw\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "94\n",
      "kawasaki quot pagemaker saved apple quot oh those were the days sxsw jwtatl enchantment\n",
      "kawasaki quot pagemaker saved apple quot oh those were the days sxsw jwtatl enchantment via mention\n",
      "\n",
      "\n",
      "new post iphone apps we will be using at south by southwest interactive link sxsw sxswi\n",
      "new post iphone apps we will be using at south by southwest interactive sxsw sxswi link\n",
      "\n",
      "\n",
      "google to launch major new social network called circles possibly today link sxsw lb via mention\n",
      "google to launch major new social network called circles possibly today link sxsw rt mention via mention\n",
      "\n",
      "\n",
      "google to launch major new social network called circles possibly today link sxsw rt mention via mention\n",
      "google to launch major new social network called circles possibly today link sxsw via mention\n",
      "\n",
      "\n",
      "google to launch major new social network called circles possibly today link sxsw\n",
      "google to launch major new social network called circles link possibly today sxsw\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting samples for tweets at various high similarity scores\n",
    "for percent in range(80,96,2):\n",
    "    counter = 0\n",
    "    print(\"\\n\")\n",
    "    print(percent)\n",
    "    for x in range(len(df)-2):\n",
    "        if counter == 5: # Taking no more than 5 pairs of tweets per %\n",
    "            counter = 0\n",
    "            break #\n",
    "        else:\n",
    "            tweet1 = df[\"processed_text\"][x]\n",
    "            tweet2  = df[\"processed_text\"][x+1]\n",
    "            emo1 = df[\"emotion\"][x]\n",
    "            emo2 = df[\"emotion\"][x+1]\n",
    "            ratio = fuzz.ratio(tweet1, tweet2)\n",
    "            if (ratio == percent) & (emo1 != emo2):\n",
    "                print(tweet1)\n",
    "                print(tweet2)\n",
    "                print(\"\\n\")\n",
    "                counter += 1\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like new useful information peters out in the high 80s with raw text. It's subjective, but that's what I have to go off of. \n",
    "\n",
    "But does that remain true if we remove all the stopwords and lemmatize the text? If stopwords are removed, that should mean that the more meaningful words are making up more of the differences between messages. So it's time to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new column out of processed_text so just the most popular (and hopefully useful) word pieces will be left behind. I left processed_text alone so I can still read something coherent.\n",
    "\n",
    "First steps: setting up the regex filter and creating an empty column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:22.856686Z",
     "start_time": "2024-04-05T08:22:22.248812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Another filter from earlier in the course\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "df[\"tokens\"] = \"\"\n",
    "for i in range(len(df)):\n",
    "    df[\"tokens\"][i] = nltk.regexp_tokenize(df[\"processed_text\"][i], pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, removing stopwords. I already jumped ahead and saw which words show up most often in the FreqDist, so I added those to the stopwords list at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:23.936201Z",
     "start_time": "2024-04-05T08:22:22.858204Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words(\"english\")\n",
    "stopwords_list += list(string.punctuation)\n",
    "stopwords_list += [str(i) for i in range(10)]\n",
    "stopwords_list += [\"sxsw\", \"link\", \"mention\"] #The top words by far\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df[\"tokens\"][i] = [w for w in df[\"tokens\"][i] if w not in stopwords_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to reduce each word to its lemma, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:23.939567Z",
     "start_time": "2024-04-05T08:22:23.937739Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:25.623652Z",
     "start_time": "2024-04-05T08:22:23.940832Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(df)-1):\n",
    "    new_sentence = []\n",
    "    for word in df[\"tokens\"][i]:\n",
    "        new_sentence.append(lemmatizer.lemmatize(word))\n",
    "    df[\"tokens\"][i] = new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:25.718418Z",
     "start_time": "2024-04-05T08:22:25.624764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ipad', 2961),\n",
       " ('rt', 2935),\n",
       " ('google', 2616),\n",
       " ('apple', 2309),\n",
       " ('quot', 1657),\n",
       " ('iphone', 1559)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = []\n",
    "for i in range(len(df)-1):\n",
    "    for w in df[\"tokens\"][i]:\n",
    "        all_tokens.append(w)\n",
    "\n",
    "freq = FreqDist(all_tokens)\n",
    "freq.most_common(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to leave \"quot\" and \"rt\" in case people link to things, quote people, or retweet more often based on a particular emotional reaction to those things.\n",
    "\n",
    "Now how often do similar texts have different categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:28.322280Z",
     "start_time": "2024-04-05T08:22:25.719569Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85%ers match 0.7779751332149201 of the time\n",
      "86%ers match 0.7807971014492754 of the time\n",
      "87%ers match 0.7844990548204159 of the time\n",
      "88%ers match 0.7883495145631068 of the time\n",
      "89%ers match 0.7814432989690722 of the time\n",
      "90%ers match 0.7871396895787139 of the time\n",
      "91%ers match 0.789838337182448 of the time\n",
      "92%ers match 0.7878787878787878 of the time\n",
      "93%ers match 0.7890173410404624 of the time\n",
      "94%ers match 0.7917981072555205 of the time\n",
      "95%ers match 0.7842465753424658 of the time\n",
      "96%ers match 0.7887931034482759 of the time\n",
      "97%ers match 0.791907514450867 of the time\n",
      "98%ers match 0.8035714285714286 of the time\n",
      "99%ers match 0.8035714285714286 of the time\n",
      "100%ers match 0.8035714285714286 of the time\n"
     ]
    }
   ],
   "source": [
    "# Just like before, but more granularly\n",
    "for percent in range(85,101):\n",
    "    diff_emo = 0\n",
    "    dupes = 0\n",
    "    for x in range(len(df)-2):\n",
    "        tweet1 = df[\"tokens\"][x]\n",
    "        tweet2  = df[\"tokens\"][x+1]\n",
    "        emo1 = df[\"emotion\"][x]\n",
    "        emo2 = df[\"emotion\"][x+1]\n",
    "        ratio = fuzz.ratio(tweet1, tweet2)\n",
    "        if (ratio >= percent) & (emo1 == emo2):\n",
    "            dupes += 1\n",
    "            diff_emo += 1\n",
    "        elif ratio >= percent:\n",
    "            dupes += 1\n",
    "        else:\n",
    "            pass\n",
    "    print(str(percent) + \"%ers match \" + str(diff_emo/dupes) + \" of the time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:36.184742Z",
     "start_time": "2024-04-05T08:24:36.175426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wesley',\n",
       " 'g',\n",
       " 'iphone',\n",
       " 'hr',\n",
       " 'tweeting',\n",
       " 'rise',\n",
       " 'austin',\n",
       " 'dead',\n",
       " 'need',\n",
       " 'upgrade',\n",
       " 'plugin',\n",
       " 'station']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokens\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this seems to be about the same. Maybe a 1% improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:22:28.513858Z",
     "start_time": "2024-04-05T08:22:28.323437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['line', 'apple', 'store', 'ipad']\n",
      "['line', 'apple', 'store', 'ipad', 'day']\n",
      "Not positive\n",
      "Positive\n",
      "89\n",
      "\n",
      "\n",
      "['apple', 'set', 'open', 'popup', 'shop', 'core', 'action', 'apple']\n",
      "['apple', 'set', 'open', 'popup', 'shop', 'core', 'action', 'apple', 'ipad', 'retail']\n",
      "Not positive\n",
      "Positive\n",
      "89\n",
      "\n",
      "\n",
      "['google', 'map', 'usage', 'mobile', 'yowza']\n",
      "['google', 'map', 'usage', 'mobile']\n",
      "Positive\n",
      "Not positive\n",
      "89\n",
      "\n",
      "\n",
      "['google', 'map', 'use', 'mobile']\n",
      "['google', 'map', 'use', 'mobile', 'marissamayer']\n",
      "Not positive\n",
      "Positive\n",
      "89\n",
      "\n",
      "\n",
      "['rt', 'presentation', 'demonstrates', 'pause', 'video', 'new', 'video', 'player', 'pick', 'spot', 'ipad', 'app', 'tveverywhere']\n",
      "['rt', 'preso', 'demonstrates', 'pause', 'video', 'new', 'video', 'player', 'amp', 'pick', 'spot', 'ipad', 'app', 'tveverywhere']\n",
      "Positive\n",
      "Not positive\n",
      "89\n",
      "\n",
      "\n",
      "['rt', 'new', 'ubersocial', 'iphone', 'app', 'store', 'includes', 'uberguide', 'got']\n",
      "['rt', 'new', 'ubersocial', 'iphone', 'app', 'store', 'includes', 'uberguide', 'sponsored']\n",
      "Positive\n",
      "Not positive\n",
      "89\n",
      "\n",
      "\n",
      "['rt', 'rt', 'google', 'launch', 'major', 'new', 'social', 'network', 'called', 'circle', 'possibly', 'today', 'cool']\n",
      "['rt', 'rt', 'google', 'launch', 'major', 'new', 'social', 'network', 'called', 'circle', 'possibly', 'today', 'via', 'pcbuzz']\n",
      "Not positive\n",
      "Positive\n",
      "89\n",
      "\n",
      "\n",
      "['rt', 'rt', 'google', 'launch', 'major', 'new', 'social', 'network', 'called', 'circle', 'possibly', 'today', 'via', 'pcbuzz']\n",
      "['rt', 'rt', 'google', 'launch', 'major', 'new', 'social', 'network', 'called', 'circle', 'possibly', 'today', 'sxswi']\n",
      "Positive\n",
      "Not positive\n",
      "89\n",
      "\n",
      "\n",
      "['rt', 'ipad', 'take', 'video', 'sxswi']\n",
      "['rt', 'ipad', 'take', 'video']\n",
      "Positive\n",
      "Not positive\n",
      "89\n",
      "\n",
      "\n",
      "['going', 'today', 'share', 'photo', 'video', 'ireport', 'cnn', 'iphone', 'app']\n",
      "['friend', 'going', 'today', 'share', 'photo', 'video', 'cnn', 'iphone', 'app']\n",
      "Positive\n",
      "Not positive\n",
      "89\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here are all the adjacent 89s for reference.\n",
    "for x in range(len(df)-2):\n",
    "    tweet1 = df[\"tokens\"][x]\n",
    "    tweet2  = df[\"tokens\"][x+1]\n",
    "    emo1 = df[\"emotion\"][x]\n",
    "    emo2 = df[\"emotion\"][x+1]\n",
    "    ratio = fuzz.ratio(tweet1, tweet2)\n",
    "    if (ratio ==89) & (emo1 != emo2):\n",
    "        print(tweet1)\n",
    "        print(tweet2)\n",
    "        print(emo1)\n",
    "        print(emo2)\n",
    "        print(ratio)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the difference is in just a word or two. Sometimes it makes sense (adding \"good\" to a message makes it positive) and other times it's just a transposition of letters or adding a name. So at this % range there's a mix of reasons why messages are different. To be fair, I'll set the bar at 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset\n",
    "#### I am going to run an experiment: I'll train one model with the most \"ambiguous\" texts removed, and train one model without removing anything. My prediction is that the model that is trained without those edge cases will have an easier time differentiating one from another, even with a slightly smaller corpus to draw from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Identify the similar tweets and set their IDs aside.\n",
    "\n",
    "Step 2: In the interim, find out how many words show up more than once. If there are at least a few thousand, then those I'll remove words that show up only once.\n",
    "\n",
    "Step 3: Create a duplicate DF and remove the ambiguous tweets from just one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.401556Z",
     "start_time": "2024-04-05T08:22:28.515111Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-408cd9b396a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtweet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtweet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0mnew_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# isolating ones with different emotions but high similarity\n",
    "ambig_emo = []\n",
    "for x in range(len(df)-2):\n",
    "        tweet1 = df[\"tokens\"][x]\n",
    "        for y in range(len(df)-1):\n",
    "            tweet2 = df[\"tokens\"][y]\n",
    "            ratio = fuzz.ratio(tweet1, tweet2)\n",
    "            if ratio < 89:\n",
    "                pass\n",
    "            elif df[\"emotion\"][x] == df[\"emotion\"][y]:\n",
    "                pass\n",
    "            elif x==y:\n",
    "                pass\n",
    "            else:\n",
    "                ambig_emo.append(x)\n",
    "                ambig_emo.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.429033Z",
     "start_time": "2024-04-05T08:22:13.250Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What fraction of my data is that?\n",
    "print(len(set(ambig_emo)))\n",
    "print(len(set(ambig_emo))/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's almost 1/6th of my data. This definitely had me speculating that the models would have a pretty sizable difference in their performance, one way or the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.429996Z",
     "start_time": "2024-04-05T08:22:13.251Z"
    }
   },
   "outputs": [],
   "source": [
    "# How many words appear more than once?\n",
    "single_words = 0\n",
    "for i in list(freq.values()):\n",
    "    if i == 1:\n",
    "        single_words += 1\n",
    "\n",
    "#The entire frequency distribution minus the words which only appear once.\n",
    "print(len(freq)-single_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuition tells me that nearly 5000 words should be enough to work with, but I am out of my depth to make that judgment. It might not help that the tweets are so short, but that's a problem for another day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.431530Z",
     "start_time": "2024-04-05T08:22:13.252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collecting the common words so I can filter everything else out\n",
    "common_words = []\n",
    "for item in freq.most_common(4806):\n",
    "    common_words.append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.433337Z",
     "start_time": "2024-04-05T08:22:13.253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Editing the tokens column to only include those common words\n",
    "for i in range(len(df)):\n",
    "    df[\"tokens\"][i] = [w for w in df[\"tokens\"][i] if w in common_words]\n",
    "    df[\"tokens\"][i] = \" \".join(df[\"tokens\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here it is, the mitosis event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.435545Z",
     "start_time": "2024-04-05T08:22:13.254Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"sdf\" will be the dataframe with edge cases removed. s = small/secondary\n",
    "sdf = df.copy()\n",
    "\n",
    "# Cutting the \"ambiguous\" ones\n",
    "sdf.drop(sdf.index[ambig_emo], inplace = True)\n",
    "sdf.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: In the next section, I will be adjusting the df and sdf in parallel, mirroring one another in the same cells. Whenever I am mirroring the code for the two, the duplicate code will be simply labeled with \"#s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It hasn't yet been made explicitly clear to me when a simple Count Vectorizer is ever more effective at this task than a TF-IDF Vectorizer. So I will be testing them both. In addition, and partly to demonstrate to myself that these classifiers are indeed much more powerful than those I learned when I was even newer to the field, I'll also generate a Random Forest model.\n",
    "\n",
    "If anything, having the third set of results can give me perspective into how much the difference there actually is between Count and TF IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.437042Z",
     "start_time": "2024-04-05T08:22:13.256Z"
    }
   },
   "outputs": [],
   "source": [
    "#The tokens used by my untrimmed dataframe\n",
    "df_tokens = []\n",
    "for i in range(len(df)):\n",
    "    df_tokens.append(df[\"tokens\"][i])\n",
    "\n",
    "#s    \n",
    "sdf_tokens = []\n",
    "for i in range(len(sdf)):\n",
    "     sdf_tokens.append(sdf[\"tokens\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.439727Z",
     "start_time": "2024-04-05T08:22:13.257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the features in preparation for the train-test split\n",
    "X = df_tokens\n",
    "y = df[['emotion']]\n",
    "#s\n",
    "X_s = sdf_tokens\n",
    "y_s = sdf[[\"emotion\"]]\n",
    "\n",
    "# Training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                 random_state=42)\n",
    "#s\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(X_s, y_s,\n",
    "                                                        random_state=4)\n",
    "\n",
    "# Taking the training set and further splitting it into a secondary\n",
    "#training set and a new validation set.\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train, y_train, \n",
    "                                              random_state=42)\n",
    "#s\n",
    "Xs_train2, Xs_test2, ys_train2, ys_test2 = train_test_split(Xs_train, \n",
    "                                                ys_train, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If my dataset was extremely large, I would have switched to a Hashing Vectorizer. At this size, performance shouldn't be affected noticeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.441418Z",
     "start_time": "2024-04-05T08:22:13.258Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=4816)\n",
    "#s\n",
    "cvs = CountVectorizer(max_features=4816)\n",
    "\n",
    "# Fit-transforming onto the validation set's training data\n",
    "X_train2_vec = cv.fit_transform(X_train2)\n",
    "#s\n",
    "Xs_train2_vec = cvs.fit_transform(Xs_train2)\n",
    "\n",
    "# Transforming the validation set\n",
    "X_test2_vec = cv.transform(X_test2)\n",
    "#s\n",
    "Xs_test2_vec = cvs.transform(Xs_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.443124Z",
     "start_time": "2024-04-05T08:22:13.259Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Initializing Naive Bayes classifiers\n",
    "mnb_cv = MultinomialNB()\n",
    "mnb_cv.fit(X_train2_vec, y_train2[\"emotion\"].ravel())\n",
    "#s\n",
    "mnb_cvs = MultinomialNB()\n",
    "mnb_cvs.fit(Xs_train2_vec, ys_train2[\"emotion\"].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.444380Z",
     "start_time": "2024-04-05T08:22:13.260Z"
    }
   },
   "outputs": [],
   "source": [
    "#Getting an accuracy score for the first classifier...\n",
    "y_hat_cv = mnb_cv.predict(X_test2_vec)\n",
    "acc_cv = str(accuracy_score(y_test2, y_hat_cv))\n",
    "print(\"accuracy 'cv' = \" + acc_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "71.96% accuracy for the Count Vectorizer on the unchanged DF. This doesn't seem like a good result, considering the fact that this is only a little better than blindly guessing the majority class every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.446539Z",
     "start_time": "2024-04-05T08:22:13.261Z"
    }
   },
   "outputs": [],
   "source": [
    "# The majority class is how big again?\n",
    "y_test2.value_counts()[0]/len(y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouch. What does the confusion matrix look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.447518Z",
     "start_time": "2024-04-05T08:22:13.262Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm_cv = confusion_matrix(y_test2, y_hat_cv)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_cv, \n",
    "                       display_labels=mnb_cv.classes_).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall for nonpositives is really good (over 80%!) but it is having a lot of trouble giving me a pool of likely-positive tweets to sift through.\n",
    "\n",
    "Did the secondary DF fare better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.448392Z",
     "start_time": "2024-04-05T08:22:13.263Z"
    }
   },
   "outputs": [],
   "source": [
    "ys_hat_cv = mnb_cvs.predict(Xs_test2_vec)\n",
    "acc_cvs = str(accuracy_score(ys_test2, ys_hat_cv))\n",
    "print(\"accuracy 'cvs'= \" + acc_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.449378Z",
     "start_time": "2024-04-05T08:22:13.264Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm_cvs = confusion_matrix(ys_test2, ys_hat_cv)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_cvs, \n",
    "                       display_labels=mnb_cvs.classes_).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! All that work paid off. 2% is 2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score to beat is 73.9% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.450321Z",
     "start_time": "2024-04-05T08:22:13.265Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(max_features=4816, lowercase = False)\n",
    "#s\n",
    "tfs = TfidfVectorizer(max_features=4816, lowercase = False)\n",
    "\n",
    "# Fit-transforming onto the validation set's training data\n",
    "X_train2_tf_vec = tf.fit_transform(X_train2)\n",
    "#s\n",
    "Xs_train2_tf_vec = tfs.fit_transform(Xs_train2)\n",
    "\n",
    "# Transforming the validation set\n",
    "X_test2_tf_vec = tf.transform(X_test2)\n",
    "#s\n",
    "Xs_test2_tf_vec = tfs.transform(Xs_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.450984Z",
     "start_time": "2024-04-05T08:22:13.266Z"
    }
   },
   "outputs": [],
   "source": [
    "mnb_tf = MultinomialNB()\n",
    "mnb_tf.fit(X_train2_tf_vec, y_train2[\"emotion\"].ravel())\n",
    "\n",
    "y_hat_tf = mnb_tf.predict(X_test2_tf_vec)\n",
    "acc_df = str(accuracy_score(y_test2, y_hat_tf))\n",
    "print(\"accuracy, TF-IDF for df= \" + acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.452009Z",
     "start_time": "2024-04-05T08:22:13.267Z"
    }
   },
   "outputs": [],
   "source": [
    "cm_tf = confusion_matrix(y_test2, y_hat_tf)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_tf, \n",
    "                       display_labels=mnb_tf.classes_).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72.15% accuracy. Not quite good enough. Its recall for the minority class is downright horrible, too. I thought for sure the more sophisticated classifier would outperform here. Well, did it do any better with the shorter DF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.453148Z",
     "start_time": "2024-04-05T08:22:13.268Z"
    }
   },
   "outputs": [],
   "source": [
    "mnb_tfs = MultinomialNB()\n",
    "mnb_tfs.fit(Xs_train2_tf_vec, ys_train2[\"emotion\"].ravel())\n",
    "\n",
    "ys_hat_tf = mnb_tfs.predict(Xs_test2_tf_vec)\n",
    "acc_sdf = str(accuracy_score(ys_test2, ys_hat_tf))\n",
    "print(\"accuracy TF-IDF for 'sdf'= \" + acc_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.454089Z",
     "start_time": "2024-04-05T08:22:13.268Z"
    }
   },
   "outputs": [],
   "source": [
    "cm_tfs = confusion_matrix(ys_test2, ys_hat_tf)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_tfs, \n",
    "                       display_labels=mnb_tfs.classes_).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73.8%. At first this seemed like a virtual tie with the other classifier (73.9) but the TF-IDF vectorizers have been giving me just putrid recall numbers. I think that even if it had a slightly better accuracy score than the CVs, I'd still have to turn it away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So the Count vectorizer on the secondary DF is the winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (for perspective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a completely new data scientist, I think it would be useful for my education to try an unrelated estimator so I can see just how much better the nltk estimators are at this job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.455325Z",
     "start_time": "2024-04-05T08:22:13.270Z"
    }
   },
   "outputs": [],
   "source": [
    "#I did originally run this cell with a wider and more varied spread of params,\n",
    "#and a cv value of 3. To save time rerunning repeatedly, I pared each down.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "\"n_estimators\": [40, 75, 120],\n",
    "\"max_depth\": [2, 4, 7],\n",
    "\"min_samples_split\": [3, 5, 10],\n",
    "\"random_state\": [1]}\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rfs = RandomForestClassifier()\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    rf, param_grid=param_grid, cv = 2, \n",
    "    return_train_score=True).fit(X_train2_vec, y_train2[\"emotion\"].ravel())\n",
    "\n",
    "rfs_grid = GridSearchCV(\n",
    "    rfs, param_grid=param_grid, cv = 2, \n",
    "    return_train_score=True).fit(Xs_train2_vec, ys_train2[\"emotion\"].ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.456341Z",
     "start_time": "2024-04-05T08:22:13.271Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"df best features = \" + str(rf_grid.best_params_))\n",
    "print(\"sdf best features = \" + str(rfs_grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.457127Z",
     "start_time": "2024-04-05T08:22:13.272Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=120, \n",
    "                            max_depth= 7, min_samples_split= 10)\n",
    "\n",
    "rf.fit(X_train2_vec, y_train2[\"emotion\"].ravel())\n",
    "y_hat = rf.predict(X_test2_vec)\n",
    "print(\"original df accuracy score = \" + str(accuracy_score(y_hat, y_test2)))\n",
    "\n",
    "\n",
    "#s\n",
    "rfs = RandomForestClassifier(n_estimators=40, \n",
    "                             max_depth= 7, min_samples_split= 3)\n",
    "\n",
    "rfs.fit(Xs_train2_vec, ys_train2[\"emotion\"].ravel())\n",
    "ys_hat = rfs.predict(Xs_test2_vec)\n",
    "print(\"sdf accuracy score = \" + str(accuracy_score(ys_hat, ys_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the RF was easily outcompeted by the NLP-specific classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the TF IDF classifier that we found before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.458022Z",
     "start_time": "2024-04-05T08:22:13.273Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_final = CountVectorizer(max_features=4816, lowercase = False)\n",
    "\n",
    "final_train_vectors = tf_final.fit_transform(Xs_train)\n",
    "\n",
    "final_test_vectors = tf_final.transform(Xs_test)\n",
    "\n",
    "final_mnb = MultinomialNB()\n",
    "\n",
    "\n",
    "final_mnb.fit(final_train_vectors, ys_train[\"emotion\"].ravel())\n",
    "\n",
    "y_hat_final = final_mnb.predict(final_test_vectors)\n",
    "acc_final = str(accuracy_score(y_hat_final, ys_test))\n",
    "\n",
    "print(\"final accuracy = \" + acc_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T08:24:28.458897Z",
     "start_time": "2024-04-05T08:22:13.274Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm_final = confusion_matrix(ys_test, y_hat_final)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_final, \n",
    "                       display_labels=final_mnb.classes_).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "73.2% is a near-negligible drop off of only 0.7% compared to the training set. And just like the other CV-built models, this one has \"decent\" recall and precision for finding positive results, but nothing to write home about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Thankfully, my final model did almost exactly as well on the unseen data as it did on all of my trails. Still, this is far too close to the about 2/3s baseline that the majority class set for me.\n",
    "\n",
    "I'm pretty sure I understand that a recommendation would be something like \"find out what negative things happened at that year's festival\" and the next steps are advice to the tech team about what could be done to improve the process\n",
    "\n",
    "#### Recommendations: \n",
    "For future marketing, it may be helpful to know what pairs of words were most associated with positive experiences and hype going into the event. Most relevant in my opinion would be 'ipad' + 'app' (showing that people really do respond to platform exclusives) and 'marissa' 'mayer' (showing that she probably brings with her a lot of goodwill. Maybe bring her back for some announcements?)\n",
    "\n",
    "Moving forward you should also broaden your focus to what people disliked about the event.\n",
    "\n",
    "The most telling negatively associated pair of words was \"google\" + \"circle\". New social media enterprises generate more groans than interest.\n",
    "\n",
    "\n",
    "#### The Next Steps:\n",
    "\n",
    "Future processing should iterate to find the most accurate boundary between fuzzy tweets.\n",
    "\n",
    "Tweets might not have enough information to generalize from. That, or they are so volatile thanks to the impact one word can have on so few characters. Either way, one should try to scrape data from social media apps with more long form engagement patterns.\n",
    "\n",
    "I suspect that the data was soured by poor inter-rater reliability. If resources could be put into that I imagine that would be a big help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd07168de47e55f922642e821276e82e1ba59be8ba89f9afd7a9ad5fcf10172704f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
